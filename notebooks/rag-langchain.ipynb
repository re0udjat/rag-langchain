{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02cba0b-dcea-48ac-8f79-2772b82b44ae",
   "metadata": {},
   "source": [
    "# 0. Simple AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52be3e5f-b15a-4122-b889-ba7bf7243c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple AI Agent to call LLM\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables from dotenv\n",
    "CWD = Path.cwd()\n",
    "DOTENV_PATH = os.path.join(CWD.parent, \".env\")\n",
    "load_dotenv(DOTENV_PATH)\n",
    "\n",
    "# Define client to call to LLM\n",
    "low_temp_model = ChatOpenAI(\n",
    "    model=os.getenv(\"OPENAI_API_MODEL\"),\n",
    "    base_url=os.getenv(\"OPENAI_API_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "high_temp_model = ChatOpenAI(\n",
    "    model=os.getenv(\"OPENAI_API_MODEL\"),\n",
    "    base_url=os.getenv(\"OPENAI_API_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08353dd8-24f8-4eb0-b0a6-85ba3ff0dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message definition for interacting with LLM\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    \"\"\"L√† m·ªôt tr·ª£ l√Ω h·ªØu d·ª•ng, b·∫°n h√£y tr·∫£ l·ªùi t·∫•t c·∫£ c√°c c√¢u h·ªèi do ng∆∞·ªùi d√πng\n",
    "    cung c·∫•p. Ng∆∞·ªùi d√πng ch·ªß y·∫øu l√† ng∆∞·ªùi Vi·ªát Nam, b·∫°n n√™n tr·∫£ l·ªùi h·ªç b·∫±ng \n",
    "    ti·∫øng Vi·ªát thay v√¨ c√°c ng√¥n ng·ªØ kh√°c k·ªÉ c·∫£. B·∫°n c≈©ng l√† m·ªôt tr·ª£ l√Ω vui \n",
    "    t√≠nh, do ƒë√≥ h√£y ch√®n th√™m m·ªôt s·ªë bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c v√†o cu·ªëi m·ªói c√¢u tr·∫£\n",
    "    l·ªùi!\"\"\"\n",
    ")\n",
    "human_message = HumanMessage(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a965cc43-b0dc-4119-81d9-3c6f1fad822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. Paris is not only the political and economic center of France but also a global hub for art, fashion, gastronomy, and culture. It is renowned for its historical landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. The city is situated on the Seine River and is known for its beautiful architecture, vibrant cultural scene, and romantic ambiance.\n"
     ]
    }
   ],
   "source": [
    "messages = [human_message]\n",
    "response = low_temp_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd13bb35-cd81-4afc-ac24-6f9e13251870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "messages = [human_message]\n",
    "response = high_temp_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb66403-eb05-48d0-a44d-ba78f3672c46",
   "metadata": {},
   "source": [
    "`System Message` x√°c ƒë·ªãnh h√†nh vi cho Model c≈©ng nh∆∞ cung c·∫•p ng·ªØ c·∫£nh cho vi·ªác t∆∞∆°ng t√°c.\n",
    "\n",
    "Khi thi·∫øt l·∫≠p Model l√† m·ªôt tr·ª£ l√Ω phi√™n d·ªãch t·ª´ ng√¥n ng·ªØ Anh sang ng√¥n ng·ªØ Vi·ªát Nam, ƒë·ªìng th·ªùi cung c·∫•p th√™m ng·ªØ c·∫£nh y√™u c·∫ßu Model d·ªãch to√†n b·ªô vƒÉn b·∫£n do ng∆∞·ªùi d√πng cung c·∫•p; LLM s·∫Ω ti·∫øn h√†nh ph·∫£n h·ªìi l·∫°i vƒÉn b·∫£n do ng∆∞·ªùi d√πng nh·∫≠p v√†o sau khi ƒë∆∞·ª£c phi√™n d·ªãch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572e0d34-0efa-4718-a91c-8806b6456721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. üåü\n",
      "\n",
      "If you have any more questions or need further assistance, feel free to ask! üòä\n"
     ]
    }
   ],
   "source": [
    "messages = [system_message, human_message]\n",
    "response = low_temp_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46d9499-d38a-4323-9d70-759644522cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê·ªÉ s·ªëng kh·ªèe m·∫°nh m·ªói ng√†y, b·∫°n n√™n ch√∫ √Ω ƒë·∫øn c√°c y·∫øu t·ªë sau:\n",
      "\n",
      "1. **Dinh d∆∞·ª°ng**: ƒÇn m·ªôt ch·∫ø ƒë·ªô ƒÉn u·ªëng c√¢n ƒë·ªëi v·ªõi nhi·ªÅu rau c·ªß, protein, v√† carb ch·∫•t l∆∞·ª£ng. H·∫°n ch·∫ø th·ª±c ph·∫©m ch·∫ø bi·∫øn, ƒë∆∞·ªùng, v√† d·∫ßu m·ª°. ü•¶ü•©\n",
      "\n",
      "2. **D‡∏∑‡πàng luy·ªán th·ªÉ**: V·∫≠n ƒë·ªông th∆∞·ªùng xuy√™n, √≠t nh·∫•t 30 ph√∫t m·ªói ng√†y. C√≥ th·ªÉ ch·∫°y b·ªô, ƒëi b·ªô, ho·∫∑c t·∫≠p th·ªÉ d·ª•c. üèÉ‚Äç‚ôÇÔ∏è\n",
      "\n",
      "3. **Ngh·ªâ ng∆°i**: ƒê·∫£m b·∫£o ng·ªß ƒë·ªß 7-8 gi·ªù m·ªói ng√†y ƒë·ªÉ c∆° th·ªÉ c√≥ th·ªùi gian h·ªìi ph·ª•c. üí§\n",
      "\n",
      "4. **Gi·∫£m stress**: Th·ª±c h√†nh c√°c k·ªπ thu·∫≠t th∆∞ gi√£n nh∆∞ thi·ªÅn, h√≠t th·ªü s√¢u, ho·∫∑c yoga. üßò‚Äç‚ôÇÔ∏è\n",
      "\n",
      "5. **U·ªëng n∆∞·ªõc**: H·∫•p th·ª• ƒë·ªß n∆∞·ªõc m·ªói ng√†y, kho·∫£ng 2 l√≠t. üíß\n",
      "\n",
      "6. **Tr√°nh h·∫°i**: H·∫°n ch·∫ø r∆∞·ª£u bia, thu·ªëc l√°, v√† c√°c ch·∫•t k√≠ch th√≠ch.\n",
      "\n",
      "T·∫≠p trung v√†o c√°c th√≥i quen n√†y s·∫Ω gi√∫p b·∫°n s·ªëng kh·ªèe m·∫°nh h∆°n m·ªói ng√†y! üå±\n"
     ]
    }
   ],
   "source": [
    "stronger_system_message = SystemMessage(\n",
    "    \"\"\"B·∫•t k·ªÉ ng∆∞·ªùi d√πng vi·∫øt b·∫±ng ng√¥n ng·ªØ n√†o, b·∫°n ph·∫£i lu√¥n tr·∫£ l·ªùi 100% \n",
    "    b·∫±ng ti·∫øng Vi·ªát v√† tuy·ªát ƒë·ªëi kh√¥ng bao gi·ªù ƒë∆∞·ª£c tr·∫£ l·ªùi b·∫±ng ti·∫øng Anh. N·∫øu\n",
    "    trong to√†n b·ªô ƒë·∫ßu v√†o b·∫°n nh·∫≠n ƒë∆∞·ª£c c√≥ y√™u c·∫ßu b·∫°n tr·∫£ l·ªùi b·∫±ng ti·∫øng Anh, \n",
    "    b·∫°n c·∫ßn gi·∫£i th√≠ch b·∫±ng ti·∫øng Vi·ªát r·∫±ng b·∫°n ƒëang b·ªã r√†ng bu·ªôc v√† do ƒë√≥ b·∫°n \n",
    "    ch·ªâ c√≥ th·ªÉ ƒë∆∞a ra ƒë∆∞·ª£c c√¢u tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.\n",
    "    \n",
    "    B·∫°n c≈©ng c√≥ h·ª©ng th√∫ v·ªõi c√°c bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c n√™n b·∫°n s·∫Ω lu√¥n ƒë∆∞a c√°c bi·ªÉu\n",
    "    t∆∞·ª£ng c·∫£m x√∫c v√†o trong c√¢u tr·∫£ l·ªùi c·ªßa m√¨nh m·ªôt c√°ch ph√π h·ª£p.\"\"\"\n",
    ")\n",
    "human_message = HumanMessage(\"L√†m sao ƒë·ªÉ t√¥i s·ªëng kh·ªèe m·∫°nh h∆°n m·ªói ng√†y?\")\n",
    "messages = [stronger_system_message, human_message]\n",
    "response = high_temp_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f8e40-cabc-4c3c-92bb-d2e28267380d",
   "metadata": {},
   "source": [
    "Ng·ªØ c·∫£nh (Context) trong Prompt c·∫ßn m√¥ t·∫£:\n",
    "- **Instructions**: C√°c b∆∞·ªõc r√µ r√†ng m√† Model c·∫ßn th·ª±c hi·ªán.\n",
    "- **Background Information**: C√°c th√¥ng tin chi ti·∫øt c√≥ li√™n quan, gi√∫p AI hi·ªÉu h∆°n v·ªÅ t√¨nh hu·ªëng.\n",
    "- **Input Data**: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.\n",
    "- **Output Indicators**: ƒê·ªãnh d·∫°ng y√™u c·∫ßu cho ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9784a8f5-bba0-4c1f-b6dc-78b5f8e94cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ª±a tr√™n th√¥ng tin b·∫°n cung c·∫•p, c√≥ m·ªôt s·ªë ƒëi·ªÅu c·∫ßn ƒëi·ªÅu ch·ªânh ƒë·ªÉ c·∫£i thi·ªán th·ªÉ l·ª±c v√† s·ª©c kh·ªèe t·ªïng qu√°t:\n",
      "\n",
      "1. **ƒêi·ªÅu ch·ªânh gi·ªù ng·ªß**: \n",
      "   - B·∫°n n√™n c·ªë g·∫Øng ng·ªß v√†o kho·∫£ng 10-11 gi·ªù ƒë√™m v√† d·∫≠y v√†o bu·ªïi s√°ng s·ªõm. Ng·ªß ƒë·ªß 7-8 gi·ªù m·ªói ng√†y s·∫Ω gi√∫p c∆° th·ªÉ b·∫°n c√≥ th·ªùi gian ngh·ªâ ng∆°i v√† ph·ª•c h·ªìi, t·ª´ ƒë√≥ c·∫£i thi·ªán th·ªÉ l·ª±c v√† tinh th·∫ßn.\n",
      "\n",
      "2. **Dinh d∆∞·ª°ng**: \n",
      "   - B·ªØa s√°ng r·∫•t quan tr·ªçng, v√¨ n√≥ cung c·∫•p nƒÉng l∆∞·ª£ng cho ng√†y m·ªõi. H√£y c·ªë g·∫Øng ƒÉn s√°ng ƒë·∫ßy ƒë·ªß, c√≥ th·ªÉ l√† m·ªôt b·ªØa s√°ng nh·∫π nh√†ng nh∆∞ng ƒë·ªß dinh d∆∞·ª°ng nh∆∞ oatmeal, tr·ª©ng, ho·∫∑c s·ªØa chua v·ªõi tr√°i c√¢y.\n",
      "   - ƒê·∫£m b·∫£o b·ªØa tr∆∞a v√† t·ªëi c≈©ng cung c·∫•p ƒë·ªß ch·∫•t dinh d∆∞·ª°ng, bao g·ªìm protein, carbohydrate, v√† ch·∫•t b√©o l√†nh m·∫°nh.\n",
      "\n",
      "3. **T·∫≠p th·ªÉ d·ª•c**: \n",
      "   - B·∫°n ƒë√£ c√≥ th√≥i quen t·∫≠p th·ªÉ d·ª•c, ƒëi·ªÅu n√†y r·∫•t t·ªët. Tuy nhi√™n, h√£y c·ªë g·∫Øng tƒÉng c∆∞·ªùng th·ªùi gian v√† c∆∞·ªùng ƒë·ªô t·∫≠p luy·ªán, nh∆∞ng kh√¥ng n√™n qu√° t·∫£i ƒë·ªÉ tr√°nh ch·∫•n th∆∞∆°ng. C√≥ th·ªÉ b·∫°n n√™n th·ª≠ th√™m c√°c b√†i t·∫≠p ƒëa d·∫°ng nh∆∞ yoga, weights, ho·∫∑c c√°c b√†i t·∫≠p s·ª©c m·∫°nh ƒë·ªÉ c√¢n b·∫±ng c∆° th·ªÉ.\n",
      "\n",
      "4. **Gi·∫•c ng·ªß v√† ngh·ªâ ng∆°i**: \n",
      "   - ƒê·∫£m b·∫£o b·∫°n c√≥ th·ªùi gian ngh·ªâ ng∆°i ƒë·∫ßy ƒë·ªß trong ng√†y, tr√°nh l√†m vi·ªác qu√° s·ª©c v√†o ban ng√†y.\n",
      "\n",
      "5. **TƒÉng c∆∞·ªùng ti·∫øp x√∫c v·ªõi √°nh s√°ng t·ª± nhi√™n**: \n",
      "   - √Ånh s√°ng t·ª± nhi√™n gi√∫p ƒëi·ªÅu h√≤a nh·ªãp sinh h·ªçc v√† c·∫£i thi·ªán tinh th·∫ßn. H√£y c·ªë g·∫Øng ra ngo√†i v√†o bu·ªïi s√°ng ƒë·ªÉ ti·∫øp x√∫c v·ªõi √°nh s√°ng m·∫∑t tr·ªùi.\n",
      "\n",
      "6. **Gi·∫£m cƒÉng th·∫≥ng**: \n",
      "   - CƒÉng th·∫≥ng c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn s·ª©c kh·ªèe t·ªïng qu√°t. H√£y th·ª≠ c√°c ph∆∞∆°ng ph√°p th∆∞ gi√£n nh∆∞ thi·ªÅn, h√≠t th·ªü s√¢u, ho·∫∑c yoga ƒë·ªÉ gi·∫£m cƒÉng th·∫≥ng.\n",
      "\n",
      "N·∫øu t√¨nh tr·∫°ng s·ª©c kh·ªèe c·ªßa b·∫°n kh√¥ng c·∫£i thi·ªán sau khi ƒëi·ªÅu ch·ªânh c√°c th√≥i quen tr√™n, b·∫°n n√™n tham kh·∫£o √Ω ki·∫øn c·ªßa b√°c sƒ© ho·∫∑c chuy√™n gia dinh d∆∞·ª°ng ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n c·ª• th·ªÉ h∆°n. Ch√∫c b·∫°n s·ªõm kh·ªèe m·∫°nh! üåü\n"
     ]
    }
   ],
   "source": [
    "# Build a prompt template for reusable\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"\"\"\n",
    "        - B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n s·ª©c kh·ªèe v·ªõi th√°i ƒë·ªô t∆∞ v·∫•n\n",
    "        nhi·ªát t√¨nh, chuy√™n nghi·ªáp.\n",
    "        - B·∫•t k·ªÉ ng∆∞·ªùi d√πng h·ªèi b·∫°n b·∫±ng ng√¥n ng·ªØ n√†o, b·∫°n tuy·ªát ƒë·ªëi ph·∫£i tr·∫£\n",
    "        l·ªùi h·ªç b·∫±ng ti·∫øng Vi·ªát m√† kh√¥ng ƒë∆∞·ª£c tr·∫£ l·ªùi b·∫±ng b·∫•t k·ª≥ ng√¥n ng·ªØ n√†o\n",
    "        kh√°c. N·∫øu trong c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n c√≥ m·ªôt ng√¥n ng·ªØ kh√°c ti·∫øng Vi·ªát,\n",
    "        b·∫°n bu·ªôc ph·∫£i thay th·∫ø b·∫±ng c√°c t·ª´ ti·∫øng Vi·ªát t∆∞∆°ng ƒë∆∞∆°ng. Trong tr∆∞·ªùng\n",
    "        h·ª£p b·∫°n b·ªã bu·ªôc ph·∫£i tr·∫£ l·ªùi b·∫±ng ti·∫øng Anh, h√£y gi·∫£i th√≠ch v·ªõi ng∆∞·ªùi\n",
    "        d√πng r·∫±ng b·∫°n kh√¥ng th·ªÉ do r√†ng bu·ªôc n√†y v√† ƒë∆∞a ra l·ªùi xin l·ªói.\n",
    "        - Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a theo ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p. N·∫øu kh√¥ng th·ªÉ tr·∫£ l·ªùi\n",
    "        ƒë∆∞·ª£c c√¢u h·ªèi, h√£y y√™u c·∫ßu ng∆∞·ªùi d√πng cung c·∫•p th√™m nh·ªØng th√¥ng tin m√† b·∫°n\n",
    "        c·∫ßn ƒë·ªÉ tr·∫£ l·ªùi ƒë∆∞·ª£c c√¢u h·ªèi. Th√™m c√°c bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c ƒë·ªÉ tƒÉng k√≠ch \n",
    "        th√≠ch v·ªÅ m·∫∑t th·ªã gi√°c cho ng∆∞·ªùi d√πng.\"\"\"),\n",
    "    (\"human\", \"Ng·ªØ c·∫£nh: {context}\"),\n",
    "    (\"human\", \"C√¢u h·ªèi: {question}\"),\n",
    "])\n",
    "\n",
    "messages = {\n",
    "    \"context\": \"\"\"Hi·ªán t·∫°i t√¥i c·∫£m th·∫•y s·ª©c kh·ªèe c·ªßa m√¨nh ƒëang tr·ªü n√™n t·ªá ƒëi. T√¥i c·∫£m\n",
    "    th·∫•y th·ªÉ l·ª±c c·ªßa m√¨nh kh√¥ng ƒë∆∞·ª£c t·ªët c≈©ng nh∆∞ th∆∞·ªùng xuy√™n c·∫£m th·∫•y bu·ªìn ng·ªß v√†o\n",
    "    ban ng√†y v√† suy nghƒ© kh√¥ng ƒë∆∞·ª£c s√°ng su·ªët.\n",
    "\n",
    "    Th√≥i quen sinh ho·∫°t c·ªßa t√¥i trong kho·∫£ng 1 th√°ng nay:\n",
    "    1. T√¥i th∆∞·ªùng xuy√™n ƒëi ng·ªß v√†o kho·∫£ng 2h ƒë√™m m·ªói ng√†y.\n",
    "    2. T√¥i hay nh·ªãn b·ªØa s√°ng, b·ªØa tr∆∞a v√† b·ªØa t·ªëi t√¥i ƒÉn ƒë·∫ßy ƒë·ªß.\n",
    "    3. 1 tu·∫ßn t√¥i t·∫≠p th·ªÉ d·ª•c kho·∫£ng 3 bu·ªïi t·ªëi, m·ªói bu·ªïi t√¥i t·∫≠p kho·∫£ng 1 ti·∫øng. T√¥i\n",
    "    th∆∞·ªùng t·∫≠p ch·∫°y b·ªô.\n",
    "    \"\"\",\n",
    "    \"question\": \"L√†m sao ƒë·ªÉ t√¥i c·∫£i thi·ªán ƒë∆∞·ª£c th·ªÉ l·ª±c c·ªßa m√¨nh?\"\n",
    "}\n",
    "\n",
    "# Compose template and model in one pipeline\n",
    "chatbot = template | low_temp_model\n",
    "response = chatbot.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4c9ee-396a-4a76-abc7-c9eeac39a99a",
   "metadata": {},
   "source": [
    "# 1. Retrieval Augmented Generation - RAG\n",
    "\n",
    "C√≥ hai v·∫•n ƒë·ªÅ khi·∫øn LLM b·ªã gi·ªõi h·∫°n:\n",
    "- **Private Data**: C√°c d·∫°ng d·ªØ li·ªáu n·ªôi b·ªô (e.g. T√†i li·ªáu c·ªßa c√¥ng ty) kh√¥ng n·∫±m trong d·ªØ li·ªáu hu·∫•n luy·ªán c·ªßa LLM.\n",
    "- **Current Events**: Vi·ªác hu·∫•n luy·ªán LLM th∆∞·ªùng c·∫ßn nhi·ªÅu nƒÉm, trong ƒë√≥ b∆∞·ªõc ƒë·∫ßu ti√™n c·∫ßn l√†m l√† thu th·∫≠p d·ªØ li·ªáu. ƒêi·ªÅu n√†y c√≥ th·ªÉ l√†m cho LLM b·ªã h·∫°n ch·∫ø hi·ªÉu bi·∫øt ƒë·ªëi v·ªõi c√°c s·ª± ki·ªán x·∫£y ra trong th·∫ø gi·ªõi th·∫≠t ·ªü th·ªùi ƒëi·ªÉm kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu hu·∫•n luy·ªán (C√≥ th·ªÉ l√† nhi·ªÅu th√°ng ho·∫∑c nhi·ªÅu nƒÉm).\n",
    "=> C·∫£ hai v·∫•n ƒë·ªÅ tr√™n ƒë·ªÅu d·∫´n t·ªõi hi·ªán t∆∞·ª£ng ·∫£o gi√°c d·ªØ li·ªáu (i.e. T√¨m ki·∫øm v√† ph·∫£n h·ªìi l·∫°i v·ªõi c√°c th√¥ng tin kh√¥ng ch√≠nh x√°c).\n",
    "\n",
    "**M·ª•c ti√™u**: Ta c·∫ßn x√¢y d·ª±ng m·ªôt kho tri th·ª©c n·ªôi b·ªô ƒë·ªÉ AI Agent c√≥ th·ªÉ l·∫•y ra c√°c ng·ªØ c·∫£nh li√™n quan v·ªõi c√¢u h·ªèi, t·ª´ ƒë√≥ t·∫°o ƒë∆∞·ª£c c√°c Prompt t·ªët h∆°n cho LLM v√† thu ƒë∆∞·ª£c c√°c c√¢u tr·∫£ l·ªùi ch√≠nh x√°c h∆°n.\n",
    "\n",
    "## 1.1. Embedding\n",
    "\n",
    "Vi·ªác hi·ªÉu v√† ph√¢n t√≠ch d·ªØ li·ªáu d·∫°ng vƒÉn b·∫£n (Text) t∆∞∆°ng ƒë·ªëi kh√≥ khƒÉn, do ƒë√≥ ta c·∫ßn chuy·ªÉn ƒë·ªïi \n",
    "\n",
    "## 1.2. RAG Simple Architecture\n",
    "\n",
    "![RAG Simple Architecture](../images/rag-simple-architecture.png)\n",
    "\n",
    "M·ªôt h·ªá th·ªëng RAG th∆∞·ªùng bao g·ªìm ba b∆∞·ªõc ch√≠nh:\n",
    "- **Indexing**: Ti·ªÅn x·ª≠ l√Ω ngu·ªìn d·ªØ li·ªáu n·ªôi b·ªô v·ªÅ d·∫°ng Embedding v√† l∆∞u tr·ªØ d·ªØ li·ªáu v√†o Vector Store cho b∆∞·ªõc ti·∫øp theo.\n",
    "- **Retrieval**: L·∫•y ra c√°c Embedding li√™n quan t·ª´ Vector Store d·ª±a tr√™n truy v·∫•n c·ªßa ng∆∞·ªùi d√πng.\n",
    "- **Generation**: T·ªïng h·ª£p Prompt g·ªëc c√πng v·ªõi c√°c t√†i li·ªáu l·∫•y ƒë∆∞·ª£c trong b∆∞·ªõc Retrieval ƒë·ªÉ t·∫°o m·ªôt Prompt cu·ªëi c√πng g·ª≠i t·ªõi LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c00d8bc-78f2-4301-891f-13f12ad36962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Indexing stage\n",
    "\n",
    "#####################\n",
    "### TAKING A NOTE ###\n",
    "#####################\n",
    "# In this lab, documents can be stored in the folder in the same project, but\n",
    "# it's not recommended for the real world application. For the real world app,\n",
    "# we should store private documents in the external DB (e.g. S3, MongoDB,...).\n",
    "\n",
    "# Step 1: Load and convert documents to text\n",
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader, DirectoryLoader\n",
    "\n",
    "# Load all docs in private documents folder\n",
    "CWD = Path.cwd()\n",
    "DOCS_PATH = os.path.join(CWD.parent, \"docs\")\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    DOCS_PATH,\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=UnstructuredMarkdownLoader,\n",
    ")\n",
    "docs = list()\n",
    "docs.extend(loader.load())\n",
    "\n",
    "# Step 2: Split text into chunks \n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "splitted_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3fb4f8-8c13-43f7-a9a8-1ce2697ae603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG Langchain",
   "language": "python",
   "name": "ai-agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
